{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d346bf0a-10f5-42c5-8626-34fa543f8435",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "from itertools import product\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import dataloader, Dataset\n",
    "\n",
    "from avr_dataset import panel_dict_to_df, slot2id_distribute9, prepare_stage3_dataset\n",
    "from utils import parse_panels,parse_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2720156-a94a-494b-b82b-0c157d154671",
   "metadata": {},
   "outputs": [],
   "source": [
    "configurations = ['distribute_nine']\n",
    "split = 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ece87e4d-4d5a-4bb0-af87-84335f7a3a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ground_truth(dataset_dir: str, split: str, all_panels=True):\n",
    "    dataset_path = Path(dataset_dir)\n",
    "    all_file_stems = list(fn.stem for fn in (dataset_path / Path(configurations[0])).glob(f'*_{split}.npz'))\n",
    "    all_file_paths = [Path(dataset_path, config, base_fn) for config, base_fn in\n",
    "                      product(configurations, all_file_stems)]\n",
    "\n",
    "    full_data = []\n",
    "\n",
    "    for file_path in all_file_paths:\n",
    "        npz = np.load(file_path.with_suffix('.npz'))   \n",
    "        full_data.append({'file': str(file_path),\n",
    "                          'images': npz['image'],\n",
    "                          'target': npz['target'].item()})\n",
    "\n",
    "    return full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa648063-8628-4b9d-a727-a193030e640d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AVRCNNDataset(Dataset):\n",
    "    def __init__(self, dataset_dir, split, configurations=None):\n",
    "        self.configurations = configuations else os.listdir(dataset_dir)\n",
    "        self.dataset_path = Path(dataset_dir)\n",
    "        self.all_file_stems = list(fn.stem for fn in (self.dataset_path / Path(self.configurations[0])).glob(f'*_{split}.npz'))\n",
    "        self.all_file_paths = [Path(self.dataset_path, config, base_fn) for config, base_fn in\n",
    "                          product(self.configurations, self.all_file_stems)]\n",
    "    \n",
    "        self.data = extract_ground_truth(dataset_dir, split)\n",
    "\n",
    "    def __len__(self, idx):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e5075af9-a31b-49dc-86fb-d6e94cd8d6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = AVRCNNDataset('dataset', 'train', ['distribute_nine'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "48d3cade-6311-4cf0-b005-de00e2d7a04a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 160, 160)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]['images'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "65941d72-e56d-4b6a-93d6-dd1ce9dab72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, out_dim=256):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(1, 32, 3, stride=2),\n",
    "                                   nn.BatchNorm2d(32),\n",
    "                                   nn.ReLU())\n",
    "        self.conv2 = nn.Sequential(nn.Conv2d(32, 32, 3, stride=2),\n",
    "                                   nn.BatchNorm2d(32),\n",
    "                                   nn.ReLU())\n",
    "        self.conv3 = nn.Sequential(nn.Conv2d(32, 32, 3, stride=2),\n",
    "                                   nn.BatchNorm2d(32),\n",
    "                                   nn.ReLU())\n",
    "        self.conv4 = nn.Sequential(nn.Conv2d(32, 32, 3, stride=2),\n",
    "                                   nn.BatchNorm2d(32),\n",
    "                                   nn.ReLU())\n",
    "        self.fc = nn.Linear(32 * 9 * 9, out_dim)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = self.conv1(X)\n",
    "        X = self.conv2(X)\n",
    "        X = self.conv3(X)\n",
    "        X = self.conv4(X)\n",
    "        X = torch.flatten(X, start_dim=1)\n",
    "        X = self.fc(X)\n",
    "        return X\n",
    "\n",
    "class RelNet(nn.Module):\n",
    "    def __init__(self, input_dim=512, g_hidden=512, f_hidden=256):\n",
    "        super().__init__()\n",
    "        self.g = nn.Sequential(\n",
    "            nn.Linear(input_dim, g_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(g_hidden, g_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(g_hidden, g_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(g_hidden, g_hidden),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.f = nn.Sequential(\n",
    "            nn.Linear(g_hidden, f_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(f_hidden, f_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(f_hidden, 13),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(13, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, X, device='cpu'):\n",
    "        batch_size = X.shape[0]\n",
    "        contexts, candidates = X[:, :8, :], X[:, 8:, :]\n",
    "\n",
    "        scores = torch.zeros((batch_size, 8), dtype=torch.float, device=device)\n",
    "        for i in range(8):\n",
    "            candidate_i = candidates[:, i, :].unsqueeze(dim=1)\n",
    "            context_candidate_i = torch.cat([contexts, candidate_i], dim=1)\n",
    "            context_candidate_pairs = torch.cat([\n",
    "                context_candidate_i.repeat_interleave(9, dim=1),\n",
    "                context_candidate_i.repeat(1, 9, 1)\n",
    "            ], dim=2)\n",
    "            g_res = self.g(context_candidate_pairs)\n",
    "            g_res_sum = torch.sum(g_res, dim=1)\n",
    "            f_res = self.f(g_res_sum)\n",
    "            scores[:, i] = f_res.squeeze(1)\n",
    "        return F.softmax(scores, dim=1)\n",
    "        \n",
    "\n",
    "class CNNRelNet(nn.Module):\n",
    "    def __init__(self, embedding_dim=256, g_hidden=512, f_hidden=256):\n",
    "        super().__init__()\n",
    "        self.g_hidden = g_hidden\n",
    "        self.f_hidden = f_hidden\n",
    "        self.embedding_size = embedding_dim\n",
    "        self.n_concat = 512\n",
    "        \n",
    "        self.cnn = CNN()\n",
    "        self.relnet = RelNet()\n",
    "\n",
    "    def forward(self, X, device='cpu'):\n",
    "        batch_size = X.shape[0]\n",
    "        embeddings = torch.zeros((batch_size, 16, self.embedding_size))\n",
    "        for i in range(16):\n",
    "            panel_i = X[:, i, :, :].unsqueeze(dim=1)\n",
    "            embeddings[:, i, :] = self.cnn(panel_i)\n",
    "        scores = self.relnet(embeddings)\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8403492e-58f2-4a81-9389-8dc1ea7d6c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0338,  0.0110, -0.0198,  ...,  0.0153,  0.0668, -0.0591],\n",
      "        [-0.0338,  0.0110, -0.0198,  ...,  0.0153,  0.0668, -0.0591],\n",
      "        [-0.0338,  0.0110, -0.0198,  ...,  0.0153,  0.0668, -0.0591],\n",
      "        ...,\n",
      "        [-0.0338,  0.0110, -0.0198,  ...,  0.0153,  0.0668, -0.0591],\n",
      "        [-0.0338,  0.0110, -0.0198,  ...,  0.0153,  0.0668, -0.0591],\n",
      "        [-0.0338,  0.0110, -0.0198,  ...,  0.0153,  0.0668, -0.0591]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "tensor([[-0.0338,  0.0110, -0.0198,  ...,  0.0153,  0.0668, -0.0591],\n",
      "        [-0.0338,  0.0110, -0.0198,  ...,  0.0153,  0.0668, -0.0591],\n",
      "        [-0.0338,  0.0110, -0.0198,  ...,  0.0153,  0.0668, -0.0591],\n",
      "        ...,\n",
      "        [-0.0338,  0.0110, -0.0198,  ...,  0.0153,  0.0668, -0.0591],\n",
      "        [-0.0338,  0.0110, -0.0198,  ...,  0.0153,  0.0668, -0.0591],\n",
      "        [-0.0338,  0.0110, -0.0198,  ...,  0.0153,  0.0668, -0.0591]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "tensor([[-0.0338,  0.0110, -0.0198,  ...,  0.0153,  0.0668, -0.0591],\n",
      "        [-0.0338,  0.0110, -0.0198,  ...,  0.0153,  0.0668, -0.0591],\n",
      "        [-0.0338,  0.0110, -0.0198,  ...,  0.0153,  0.0668, -0.0591],\n",
      "        ...,\n",
      "        [-0.0338,  0.0110, -0.0198,  ...,  0.0153,  0.0668, -0.0591],\n",
      "        [-0.0338,  0.0110, -0.0198,  ...,  0.0153,  0.0668, -0.0591],\n",
      "        [-0.0338,  0.0110, -0.0198,  ...,  0.0153,  0.0668, -0.0591]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "tensor([[-0.0338,  0.0110, -0.0198,  ...,  0.0153,  0.0668, -0.0591],\n",
      "        [-0.0338,  0.0110, -0.0198,  ...,  0.0153,  0.0668, -0.0591],\n",
      "        [-0.0338,  0.0110, -0.0198,  ...,  0.0153,  0.0668, -0.0591],\n",
      "        ...,\n",
      "        [-0.0338,  0.0110, -0.0198,  ...,  0.0153,  0.0668, -0.0591],\n",
      "        [-0.0338,  0.0110, -0.0198,  ...,  0.0153,  0.0668, -0.0591],\n",
      "        [-0.0338,  0.0110, -0.0198,  ...,  0.0153,  0.0668, -0.0591]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "tensor([[-0.0338,  0.0110, -0.0198,  ...,  0.0153,  0.0668, -0.0591],\n",
      "        [-0.0338,  0.0110, -0.0198,  ...,  0.0153,  0.0668, -0.0591],\n",
      "        [-0.0338,  0.0110, -0.0198,  ...,  0.0153,  0.0668, -0.0591],\n",
      "        ...,\n",
      "        [-0.0338,  0.0110, -0.0198,  ...,  0.0153,  0.0668, -0.0591],\n",
      "        [-0.0338,  0.0110, -0.0198,  ...,  0.0153,  0.0668, -0.0591],\n",
      "        [-0.0338,  0.0110, -0.0198,  ...,  0.0153,  0.0668, -0.0591]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "tensor([[-0.0338,  0.0110, -0.0198,  ...,  0.0153,  0.0668, -0.0591],\n",
      "        [-0.0338,  0.0110, -0.0198,  ...,  0.0153,  0.0668, -0.0591],\n",
      "        [-0.0338,  0.0110, -0.0198,  ...,  0.0153,  0.0668, -0.0591],\n",
      "        ...,\n",
      "        [-0.0338,  0.0110, -0.0198,  ...,  0.0153,  0.0668, -0.0591],\n",
      "        [-0.0338,  0.0110, -0.0198,  ...,  0.0153,  0.0668, -0.0591],\n",
      "        [-0.0338,  0.0110, -0.0198,  ...,  0.0153,  0.0668, -0.0591]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "tensor([[-0.0338,  0.0110, -0.0198,  ...,  0.0153,  0.0668, -0.0591],\n",
      "        [-0.0338,  0.0110, -0.0198,  ...,  0.0153,  0.0668, -0.0591],\n",
      "        [-0.0338,  0.0110, -0.0198,  ...,  0.0153,  0.0668, -0.0591],\n",
      "        ...,\n",
      "        [-0.0338,  0.0110, -0.0198,  ...,  0.0153,  0.0668, -0.0591],\n",
      "        [-0.0338,  0.0110, -0.0198,  ...,  0.0153,  0.0668, -0.0591],\n",
      "        [-0.0338,  0.0110, -0.0198,  ...,  0.0153,  0.0668, -0.0591]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "tensor([[-0.0338,  0.0110, -0.0198,  ...,  0.0153,  0.0668, -0.0591],\n",
      "        [-0.0338,  0.0110, -0.0198,  ...,  0.0153,  0.0668, -0.0591],\n",
      "        [-0.0338,  0.0110, -0.0198,  ...,  0.0153,  0.0668, -0.0591],\n",
      "        ...,\n",
      "        [-0.0338,  0.0110, -0.0198,  ...,  0.0153,  0.0668, -0.0591],\n",
      "        [-0.0338,  0.0110, -0.0198,  ...,  0.0153,  0.0668, -0.0591],\n",
      "        [-0.0338,  0.0110, -0.0198,  ...,  0.0153,  0.0668, -0.0591]],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 8])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CNNRelNet()\n",
    "X = torch.ones((5,16,160,160), dtype=torch.float)\n",
    "model(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da83328f-b794-4a25-aa88-2f6728293bf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61097e8b-867e-4c05-b451-4c9f63fbaa99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2666f332-e8e0-4c9a-b779-fad072774730",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ce4da388-8f5b-4d4c-986e-ab89be8b48f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 2, 2, 3, 3])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1,2,3]).repeat_interleave(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a779d427-ff2e-46ef-8d49-eb3b163f778c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8e54cdc6-5934-4ad3-a397-693a3e8ff60d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 16, 256])\n",
      "\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 1., 1., 1.],\n",
      "        [0., 0., 0.,  ..., 2., 2., 2.],\n",
      "        ...,\n",
      "        [8., 8., 8.,  ..., 6., 6., 6.],\n",
      "        [8., 8., 8.,  ..., 7., 7., 7.],\n",
      "        [8., 8., 8.,  ..., 8., 8., 8.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 1., 1., 1.],\n",
      "        [0., 0., 0.,  ..., 2., 2., 2.],\n",
      "        ...,\n",
      "        [9., 9., 9.,  ..., 6., 6., 6.],\n",
      "        [9., 9., 9.,  ..., 7., 7., 7.],\n",
      "        [9., 9., 9.,  ..., 9., 9., 9.]])\n",
      "tensor([[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  ...,  1.,  1.,  1.],\n",
      "        [ 0.,  0.,  0.,  ...,  2.,  2.,  2.],\n",
      "        ...,\n",
      "        [10., 10., 10.,  ...,  6.,  6.,  6.],\n",
      "        [10., 10., 10.,  ...,  7.,  7.,  7.],\n",
      "        [10., 10., 10.,  ..., 10., 10., 10.]])\n",
      "tensor([[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  ...,  1.,  1.,  1.],\n",
      "        [ 0.,  0.,  0.,  ...,  2.,  2.,  2.],\n",
      "        ...,\n",
      "        [11., 11., 11.,  ...,  6.,  6.,  6.],\n",
      "        [11., 11., 11.,  ...,  7.,  7.,  7.],\n",
      "        [11., 11., 11.,  ..., 11., 11., 11.]])\n",
      "tensor([[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  ...,  1.,  1.,  1.],\n",
      "        [ 0.,  0.,  0.,  ...,  2.,  2.,  2.],\n",
      "        ...,\n",
      "        [12., 12., 12.,  ...,  6.,  6.,  6.],\n",
      "        [12., 12., 12.,  ...,  7.,  7.,  7.],\n",
      "        [12., 12., 12.,  ..., 12., 12., 12.]])\n",
      "tensor([[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  ...,  1.,  1.,  1.],\n",
      "        [ 0.,  0.,  0.,  ...,  2.,  2.,  2.],\n",
      "        ...,\n",
      "        [13., 13., 13.,  ...,  6.,  6.,  6.],\n",
      "        [13., 13., 13.,  ...,  7.,  7.,  7.],\n",
      "        [13., 13., 13.,  ..., 13., 13., 13.]])\n",
      "tensor([[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  ...,  1.,  1.,  1.],\n",
      "        [ 0.,  0.,  0.,  ...,  2.,  2.,  2.],\n",
      "        ...,\n",
      "        [14., 14., 14.,  ...,  6.,  6.,  6.],\n",
      "        [14., 14., 14.,  ...,  7.,  7.,  7.],\n",
      "        [14., 14., 14.,  ..., 14., 14., 14.]])\n",
      "tensor([[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  ...,  1.,  1.,  1.],\n",
      "        [ 0.,  0.,  0.,  ...,  2.,  2.,  2.],\n",
      "        ...,\n",
      "        [15., 15., 15.,  ...,  6.,  6.,  6.],\n",
      "        [15., 15., 15.,  ...,  7.,  7.,  7.],\n",
      "        [15., 15., 15.,  ..., 15., 15., 15.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 8])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RelNet()\n",
    "X = torch.tensor([[i]*256 for i in range(16)], dtype=torch.float).unsqueeze(0).repeat(10,1,1)\n",
    "print(X.shape)\n",
    "print()\n",
    "model(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6d68b82c-03fa-44e3-95d0-bbd0778743f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 512])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881b7474-8b1d-4d3e-9145-b5ead3f986dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853ca143-ea3d-4765-8777-c91ab3dba8e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35babc0-e4b9-4037-9b23-032d53f7eff8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b503f887-31cf-4c6c-b4df-0c7d2199433f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stage3RelNetV2(nn.Module):\n",
    "    def __init__(self, mlp_hidden=32, classes=8, n_candidates=8):\n",
    "        super().__init__()\n",
    "        self.n_concat = 9 * 3 * 2\n",
    "        self.mlp_hidden = mlp_hidden\n",
    "        self.n_candidates = n_candidates\n",
    "\n",
    "        self.g = nn.Sequential(\n",
    "            nn.Linear(self.n_concat, mlp_hidden),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(mlp_hidden, mlp_hidden),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(mlp_hidden, mlp_hidden),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(mlp_hidden, mlp_hidden),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "\n",
    "        self.f = nn.Sequential(\n",
    "            nn.Linear(mlp_hidden, mlp_hidden),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(mlp_hidden, mlp_hidden),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(mlp_hidden, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, X, device='cpu'):\n",
    "        X = X.float()\n",
    "        n_batch = X.size()[0]\n",
    "        contexts, candidates = X[:, :8, :], X[:, 8:, :]\n",
    "        contexts = contexts.unsqueeze(1).repeat(1, 8, 1, 1)\n",
    "        candidates = candidates.unsqueeze(1).permute(0, 2, 1, 3)\n",
    "\n",
    "        # Shape: (n_batch, n_candidates=8, n_panels=9, num_dim=22 * 3)\n",
    "        context_candidate_pairs = torch.cat([contexts, candidates], dim=2)\n",
    "\n",
    "        context_candidate_pairs1 = context_candidate_pairs.repeat_interleave(9, dim=2)\n",
    "        context_candidate_pairs2 = context_candidate_pairs.repeat(1, 1, 9, 1)\n",
    "\n",
    "        # Shape: (n_batch, n_candidates=8, n_pairs_per_candidate=9*9, num_dim=22 * 3)\n",
    "        context_candidate_concat = torch.cat([context_candidate_pairs1, context_candidate_pairs2], dim=3)\n",
    "\n",
    "        candidate_logits = torch.zeros((n_batch, self.n_candidates), dtype=torch.float).to(device)\n",
    "        for i in range(self.n_candidates):\n",
    "            # Shape: (n_batch, n_pairs_per_candidate=9*9, num_dim=22 * 3)\n",
    "            all_pairs_candidate_i = context_candidate_concat[:, i, :, :]\n",
    "            n_pairs = all_pairs_candidate_i.shape[1]\n",
    "            # Shape: (n_batch, n_pairs_per_candidate=9*9, mlp_hidden)\n",
    "            g_res = self.g(all_pairs_candidate_i)\n",
    "            g_res_sum = torch.sum(g_res, dim=1)\n",
    "\n",
    "            # Shape: (n_batch)\n",
    "            f_res = self.f(g_res_sum)\n",
    "            candidate_logits[:, i] = f_res.squeeze(1)\n",
    "        return F.softmax(candidate_logits, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e3cfb3-5531-4756-bb0e-3fdadb000653",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f061d4cf-7a8a-4504-b027-264c95dfecbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 256])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CNN()\n",
    "X = torch.ones((5,1,160,160))\n",
    "model(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55f6a490-58a3-4699-bdec-3dc321724788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(1, 4, kernel_size=(32, 32), stride=(1, 1))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Conv2d(1, 4, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb6d1ba9-125f-470f-b797-935d98093f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, params in nn.Conv2d(1, 32, 3, stride=2).named_parameters():\n",
    "    if 'conv' in name:\n",
    "        print(name, params.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4dfed0-6f50-4755-8b6b-2d8e5ef2b1f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
