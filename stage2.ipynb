{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-12T01:01:44.721452Z",
     "start_time": "2023-10-12T01:01:44.712987Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from torch.utils.data import Dataset\n",
    "from itertools import product\n",
    "import xml.etree.ElementTree as ET\n",
    "from pathlib import Path\n",
    "\n",
    "from utils import parse_rules, parse_panels, bbox_to_xyxy, plot_example\n",
    "from avr_dataset import extract_stage2_ground_truth, prepare_stage2_dataset\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from torch import optim\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "outputs": [],
   "source": [
    "class AVRStage2Dataset(nn.Module):\n",
    "    def __init__(self, dataset_dir, split):\n",
    "        super().__init__()\n",
    "        panels_df, rules_df = extract_stage2_ground_truth(dataset_dir, split)\n",
    "        self.final_df = prepare_stage2_dataset(panels_df, rules_df, merge_row=False)\n",
    "        self.final_df = self.final_df.reset_index()\n",
    "        self.info_cols = self.final_df.columns.tolist()[:2]\n",
    "        self.feature_cols = self.final_df.columns.tolist()[2:-5]\n",
    "        self.label_cols = self.final_df.columns.tolist()[-5:]\n",
    "        self.label2id = {'Constant': 0, 'Distribute_Three': 1, 'Progression': 2, 'Arithmetic': 3}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.final_df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data = self.final_df.iloc[idx]\n",
    "        \n",
    "        info = data[self.info_cols].to_dict()\n",
    "        \n",
    "        panels = torch.split(torch.tensor(data[self.feature_cols].values.astype(np.int64)), 22 * 3)\n",
    "        reshaped_panels = list(torch.stack(torch.split(p, 3)) for p in panels)\n",
    "        features = torch.stack(reshaped_panels)\n",
    "        \n",
    "        labels = data[self.label_cols].map(self.label2id).to_dict()\n",
    "        for key, val, in labels.items():\n",
    "            labels[key] = torch.tensor(val)\n",
    "        \n",
    "        return {\n",
    "            'info': info,\n",
    "            'features': features,\n",
    "            'labels': labels\n",
    "        }\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T01:01:45.450615Z",
     "start_time": "2023-10-12T01:01:45.447220Z"
    }
   },
   "id": "4464db018433a954"
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "outputs": [],
   "source": [
    "class RelationNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        mlp_hidden=32,\n",
    "        classes=4,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.n_concat = 9\n",
    "        \n",
    "        self.g = nn.Sequential(\n",
    "            nn.Linear(self.n_concat, mlp_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(mlp_hidden, mlp_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(mlp_hidden, mlp_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(mlp_hidden, mlp_hidden),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        def get_head():\n",
    "            return nn.Sequential(\n",
    "            nn.Linear(mlp_hidden, mlp_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(mlp_hidden, mlp_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(mlp_hidden, classes),\n",
    "        )\n",
    "        \n",
    "        self.mlp_hidden = mlp_hidden\n",
    "        \n",
    "        self.f_num = get_head()\n",
    "        self.f_pos = get_head()\n",
    "        self.f_type = get_head()\n",
    "        self.f_size = get_head()\n",
    "        self.f_color = get_head()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1, x2, x3, x4, x5, x6 = x[:, 0, :, :], x[:, 1, :, :], x[:, 2, :, :], x[:, 3, :, :], x[:, 4, :, :], x[:, 5, :, :]\n",
    "\n",
    "        x1_repeated = torch.repeat_interleave(x1, 22*22, dim=1)\n",
    "        x2_repeated = torch.repeat_interleave(x2, 22, dim=1).repeat(1, 22, 1)\n",
    "        x3_repeated = x3.repeat(1, 22*22, 1)\n",
    "        x_row1 = torch.cat([x1_repeated, x2_repeated, x3_repeated], dim=2).float()\n",
    "        \n",
    "        x4_repeated = torch.repeat_interleave(x4, 22*22, dim=1)\n",
    "        x5_repeated = torch.repeat_interleave(x5, 22, dim=1).repeat(1, 22, 1)\n",
    "        x6_repeated = x6.repeat(1, 22*22, 1)\n",
    "        x_row2 = torch.cat([x4_repeated, x5_repeated, x6_repeated], dim=2).float()\n",
    "        \n",
    "        g_row1 = self.g(x_row1)\n",
    "        g_row2 = self.g(x_row2)\n",
    "        g_row1 = g_row1.view(-1, 22*22*22, self.mlp_hidden).sum(1).squeeze()\n",
    "        g_row2 = g_row2.view(-1, 22*22*22, self.mlp_hidden).sum(1).squeeze()\n",
    "        \n",
    "        row1_num = self.f_num(g_row1)\n",
    "        row1_pos = self.f_pos(g_row1)\n",
    "        row1_type = self.f_type(g_row1)\n",
    "        row1_size = self.f_size(g_row1)\n",
    "        row1_color = self.f_color(g_row1)\n",
    "        \n",
    "        row2_num = self.f_num(g_row2)\n",
    "        row2_pos = self.f_pos(g_row2)\n",
    "        row2_type = self.f_type(g_row2)\n",
    "        row2_size = self.f_size(g_row2)\n",
    "        row2_color = self.f_color(g_row2)\n",
    "        \n",
    "        predictions = {\n",
    "            'num': (row1_num + row2_num) / 2,\n",
    "            'pos': (row1_pos + row2_pos) / 2,\n",
    "            'type': (row1_type + row2_type) / 2,\n",
    "            'size': (row1_size + row2_size) / 2,\n",
    "            'color': (row1_color + row2_color) / 2,\n",
    "        }\n",
    "\n",
    "        return predictions"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T01:01:46.143130Z",
     "start_time": "2023-10-12T01:01:46.140247Z"
    }
   },
   "id": "f8a137ae24f3d03e"
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "lr = 5e-6\n",
    "lr_max = 5e-4\n",
    "lr_gamma = 2\n",
    "lr_step = 20\n",
    "clip_norm = 50\n",
    "weight_decay = 1e-4\n",
    "n_epoch = 500\n",
    "n_worker = 9\n",
    "data_parallel = True"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T01:01:46.871998Z",
     "start_time": "2023-10-12T01:01:46.866651Z"
    }
   },
   "id": "bdaba7721e15ec98"
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "outputs": [],
   "source": [
    "train_dataset = AVRStage2Dataset('dataset', 'train')\n",
    "test_dataset = AVRStage2Dataset('dataset', 'test')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T01:01:53.188949Z",
     "start_time": "2023-10-12T01:01:47.826782Z"
    }
   },
   "id": "e580885b75b4d650"
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "    pbar = tqdm(iter(train_dataloader))\n",
    "\n",
    "    net.train(True)\n",
    "\n",
    "    for i, data_dict in enumerate(pbar):\n",
    "        x = data_dict['features'].cuda()\n",
    "        y = data_dict['labels']\n",
    "        for key, val in y.items():\n",
    "            y[key] = val.cuda()\n",
    "\n",
    "        net.zero_grad()\n",
    "        out = net(x)\n",
    "        loss = criterion(out['num'], y['num'])\n",
    "        for key in ['pos', 'type', 'size', 'color']:\n",
    "            loss += criterion(out[key], y[key])\n",
    "\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(net.parameters(), clip_norm)\n",
    "        optimizer.step()\n",
    "        \n",
    "        acc = {'num': 0, 'pos': 0, 'type': 0, 'size': 0, 'color': 0}\n",
    "        moving_loss = acc.copy()\n",
    "        for key in acc:\n",
    "            correct = out[key].data.cpu().numpy().argmax(1) == y['key'].data.cpu().numpy()\n",
    "            acc[key] = correct.sum() / batch_size\n",
    "            if moving_loss[key] == 0:\n",
    "                moving_loss[key] = acc[key]\n",
    "            else:\n",
    "                moving_loss[key] = moving_loss[key] * 0.99 + acc[key] * 0.01\n",
    "        avg_acc = sum(acc.values()) / 5\n",
    "\n",
    "        pbar.set_description(\n",
    "            'Epoch: {}; Loss: {:.5f}; Acc: {:.5f}; Moving Loss: {:.5f}; LR: {:.6f}'.format(\n",
    "                epoch + 1,\n",
    "                loss.detach().item(),\n",
    "                avg_acc,\n",
    "                moving_loss,\n",
    "                optimizer.param_groups[0]['lr'],\n",
    "            )\n",
    "        )\n",
    "        return moving_loss, acc"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T01:01:53.195014Z",
     "start_time": "2023-10-12T01:01:53.192017Z"
    }
   },
   "id": "e47e33e262d9c206"
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "outputs": [],
   "source": [
    "def valid(epoch):\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size, shuffle=True)\n",
    "    pbar = tqdm(iter(test_dataloader))\n",
    "    \n",
    "    net.eval()\n",
    "    num_correct = {'num': 0, 'pos': 0, 'type': 0, 'size': 0, 'color': 0}\n",
    "    acc = num_correct.copy()\n",
    "    num_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, data_dict in enumerate(pbar):\n",
    "            x = data_dict['features'].cuda()\n",
    "            y = data_dict['labels']\n",
    "            \n",
    "            out = net(x)\n",
    "            acc = {'num': 0, 'pos': 0, 'type': 0, 'size': 0, 'color': 0}\n",
    "            for key in num_correct:\n",
    "                correct = out[key].data.cpu().numpy().argmax(1) == y['key'].data.cpu().numpy()\n",
    "                num_correct[key] = correct.sum()\n",
    "            \n",
    "            num_total += batch_size\n",
    "    \n",
    "    for key in num_correct:\n",
    "        acc[key] = num_correct[key] / num_total\n",
    "\n",
    "    print('Avg Acc: {:.5f}'.format(sum(num_correct.values()) / 5))\n",
    "    \n",
    "    return acc"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T01:01:53.200795Z",
     "start_time": "2023-10-12T01:01:53.195154Z"
    }
   },
   "id": "4fcb4ae9624cfc16"
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/richardzhu/Developer/research/avr/venv/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:389: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "/Users/richardzhu/Developer/research/avr/venv/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:139: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "  0%|          | 0/26 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[217], line 16\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m scheduler\u001B[38;5;241m.\u001B[39mget_lr()[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m<\u001B[39m lr_max:\n\u001B[1;32m     14\u001B[0m     scheduler\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m---> 16\u001B[0m _, train_acc \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mepoch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     17\u001B[0m test_acc \u001B[38;5;241m=\u001B[39m valid(epoch)\n\u001B[1;32m     19\u001B[0m train_acc_list\u001B[38;5;241m.\u001B[39mappend(train_acc)\n",
      "Cell \u001B[0;32mIn[215], line 8\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(epoch)\u001B[0m\n\u001B[1;32m      5\u001B[0m net\u001B[38;5;241m.\u001B[39mtrain(\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, data_dict \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(pbar):\n\u001B[0;32m----> 8\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[43mdata_dict\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mfeatures\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcuda\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      9\u001B[0m     y \u001B[38;5;241m=\u001B[39m data_dict[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlabels\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m     10\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m key, val \u001B[38;5;129;01min\u001B[39;00m y\u001B[38;5;241m.\u001B[39mitems():\n",
      "File \u001B[0;32m~/Developer/research/avr/venv/lib/python3.10/site-packages/torch/cuda/__init__.py:239\u001B[0m, in \u001B[0;36m_lazy_init\u001B[0;34m()\u001B[0m\n\u001B[1;32m    235\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m    236\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    237\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmultiprocessing, you must use the \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mspawn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m start method\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    238\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(torch\u001B[38;5;241m.\u001B[39m_C, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_cuda_getDeviceCount\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m--> 239\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTorch not compiled with CUDA enabled\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    240\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _cudart \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    241\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\n\u001B[1;32m    242\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mAssertionError\u001B[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "net = RelationNet()\n",
    "if torch.cuda.is_available():\n",
    "    net = net.cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "scheduler = StepLR(optimizer, step_size=lr_step, gamma=lr_gamma)\n",
    "\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    if scheduler.get_lr()[0] < lr_max:\n",
    "        scheduler.step()\n",
    "\n",
    "    _, train_acc = train(epoch)\n",
    "    test_acc = valid(epoch)\n",
    "    \n",
    "    train_acc_list.append(train_acc)\n",
    "    test_acc_list.append(test_acc)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T01:02:01.248632Z",
     "start_time": "2023-10-12T01:02:00.824014Z"
    }
   },
   "id": "226ef26de7dd0c9f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "af3ef761fbf8187b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e65bae926ef22cdd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "9577c2e942eea78e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b082ac869c45dcbe"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "6258cf5c8d51a082"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "fb88ea7c4ff0c086"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "920ea71e0c99d124"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "642496d511473aa8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "eadc40e763d85dbb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e6e2495537ece047"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "36a082b9e1440c9f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SVM and XGBoost Experiments"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8112f193bff508de"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "label_columns = ['number', 'position', 'type', 'size', 'color']\n",
    "\n",
    "panels_df, rules_df = extract_stage2_ground_truth('dataset', 'train')\n",
    "final_df = prepare_stage2_dataset(panels_df, rules_df, merge_row=False)\n",
    "\n",
    "X, Y = final_df[final_df.columns[:-5]], final_df[final_df.columns[-5:]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc.fit(X)\n",
    "X_train_encoded = enc.transform(X_train).toarray()\n",
    "X_test_encoded = enc.transform(X_test).toarray()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T05:43:00.169706Z",
     "start_time": "2023-10-10T05:42:58.327622Z"
    }
   },
   "id": "196c0f51e7a93fca"
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "outputs": [
    {
     "data": {
      "text/plain": "0.4866850321395776"
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf = svm.SVC()\n",
    "clf.fit(X_train_encoded, y_train['type'].values)\n",
    "clf.score(X_test_encoded, y_test['type'].values)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T11:46:14.432584Z",
     "start_time": "2023-10-04T11:44:10.404848Z"
    }
   },
   "id": "92857b8ce59d78fc"
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "outputs": [],
   "source": [
    "label_map = {'Constant': 0, 'Distribute_Three': 1, 'Progression': 2, 'Arithmetic': 3}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T11:42:52.415442Z",
     "start_time": "2023-10-04T11:42:52.408155Z"
    }
   },
   "id": "dac0a6fa78800b53"
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "outputs": [
    {
     "data": {
      "text/plain": "0.8523875114784206"
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "bst_type = XGBClassifier(n_estimators=20, max_depth=50, learning_rate=1, objective='multi:softprob')\n",
    "bst_type.fit(X_train_encoded, y_train['type'].map(label_map).values)\n",
    "bst_type.score(X_test_encoded, y_test['type'].map(label_map).values)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T11:41:12.046048Z",
     "start_time": "2023-10-04T11:41:11.021943Z"
    }
   },
   "id": "28aa5085f940d994"
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "outputs": [
    {
     "data": {
      "text/plain": "0.6779155188246098"
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst_color = XGBClassifier(n_estimators=20, max_depth=100, learning_rate=0.1, objective='multi:softprob')\n",
    "bst_color.fit(X_train_encoded, y_train['color'].map(label_map).values)\n",
    "bst_color.score(X_test_encoded, y_test['color'].map(label_map).values)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T11:43:12.792950Z",
     "start_time": "2023-10-04T11:43:10.475419Z"
    }
   },
   "id": "ad5eb0093adfcd4f"
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "outputs": [
    {
     "data": {
      "text/plain": "0.73989898989899"
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst_size = XGBClassifier(n_estimators=20, max_depth=100, learning_rate=0.1, objective='multi:softprob')\n",
    "bst_size.fit(X_train_encoded, y_train['size'].map(label_map).values)\n",
    "bst_size.score(X_test_encoded, y_test['size'].map(label_map).values)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T11:43:52.119511Z",
     "start_time": "2023-10-04T11:43:49.829784Z"
    }
   },
   "id": "499b23ab5f7dcb41"
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "outputs": [
    {
     "data": {
      "text/plain": "0.8675390266299358"
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst_number = XGBClassifier(n_estimators=20, max_depth=100, learning_rate=0.1, objective='multi:softprob')\n",
    "bst_number.fit(X_train_encoded, y_train['number'].map(label_map).values)\n",
    "bst_number.score(X_test_encoded, y_test['number'].map(label_map).values)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T11:47:15.699031Z",
     "start_time": "2023-10-04T11:47:14.497662Z"
    }
   },
   "id": "78bcb87cd29dc7f0"
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "outputs": [
    {
     "data": {
      "text/plain": "0.8675390266299358"
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst_position = XGBClassifier(n_estimators=20, max_depth=100, learning_rate=0.1, objective='multi:softprob')\n",
    "bst_position.fit(X_train_encoded, y_train['position'].map(label_map).values)\n",
    "bst_position.score(X_test_encoded, y_test['position'].map(label_map).values)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T11:47:41.049018Z",
     "start_time": "2023-10-04T11:47:39.960715Z"
    }
   },
   "id": "891ef6b084aaa28c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "273d80c932d1f282"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
